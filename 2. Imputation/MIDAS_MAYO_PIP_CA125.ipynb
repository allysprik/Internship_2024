{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Author: Ally Sprik\n",
    "### Last-updated: 25-02-2024\n",
    "\n",
    "Goal of this notebook is to utilise MIDASpy to impute the missing values in the MAYO dataset, using PIPENDO. The imputed dataset will be used in the next steps of the analysis."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ad6894f22ce9fa6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import MIDASpy as midas\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "# get gpu available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_MAYO = pd.read_csv(\"../0.1. Cleaned_data/MAYO_subdag.csv\")\n",
    "df_PIP = pd.read_csv('../0.1. Cleaned_data/Casper_PIPENDO_Cleaned.csv', index_col='Unnamed: 0')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f9f7c14e65e2da8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Select the columns to use as imputation evidence. The columns are the same for both datasets, so we can use the same columns for both datasets."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2279c00f2e194056"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evidence_columns = [\"ER\", \"PR\", \"p53\", \"L1CAM\", \"CA125\", \"Platelets\", \"PreoperativeGrade\",\"LNM\", \"LVSI\", \"Chemotherapy\", \"Radiotherapy\", \"Survival1yr\", \"Survival3yr\", \"Survival5yr\", \"Cytology\"]\n",
    "\n",
    "\n",
    "df_MAYO = df_MAYO[evidence_columns]\n",
    "df_PIP = df_PIP[evidence_columns]\n",
    "\n",
    "# Concatenate the two datasets first MAYO then PIPENDO\n",
    "data = pd.concat([df_MAYO, df_PIP], axis=0, ignore_index=True).replace({0:'no', 1:'yes'})\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1731d0017f190e6c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set the data to categorical and encode the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f2a551f02125ddf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in data.columns:\n",
    "    data[column] = data[column].astype('category')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44570aef9b180be8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Encode the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e29f6328aef46771"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoded, cat_cols_list = midas.cat_conv(data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fd1cd7e830f4b7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the MIDAS model and train it"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93008eaf977ce806"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imputer = midas.Midas(layer_structure=[256,256,256], vae_layer=True, seed=123, input_drop=0.90, latent_space_size=64, vae_sample_var=0.8, vae_alpha=1)\n",
    "\n",
    "imputer.build_model(encoded, softmax_columns=cat_cols_list)\n",
    "imputer.train_model(training_epochs=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4595b2b7006c0754"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate the imputations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f46b96aeb83553c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imputations = imputer.generate_samples(m=10).output_list"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b2936b71e6e4d05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Decode the imputations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f73eeb0c08f874d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "flat_cats = [cat for variable in cat_cols_list for cat in variable]\n",
    "categorical = data.columns.values\n",
    "\n",
    "for i in range(len(imputations)):\n",
    "    tmp_cat = [imputations[i][x].idxmax(axis=1) for x in cat_cols_list]\n",
    "    cat_df = pd.DataFrame({categorical[i]: tmp_cat[i] for i in range(len(categorical))})\n",
    "    imputations[i] = pd.concat([imputations[i], cat_df], axis=1).drop(flat_cats, axis=1)\n",
    "for i in range(0, 10):\n",
    "    imputation = imputations[i]\n",
    "    for col in imputation.columns.values:\n",
    "        for j in range(len(imputation)):\n",
    "            imputations[i][col][j] = imputation[col][j].removeprefix(col + '_')\n",
    "            \n",
    "completed_data = imputations[9]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f87c1d722b332b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split the imputed data back into the original datasets, check if the imputed data is the same as the original data where there were values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4098be80e5ee47e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MAYO_part = completed_data.iloc[:len(df_MAYO), :]\n",
    "PIP_part = completed_data.iloc[len(df_MAYO):, :]\n",
    "\n",
    "for col in evidence_columns:\n",
    "    temp = df_MAYO[col].dropna()\n",
    "    index = temp.index\n",
    "    temppart = MAYO_part[col].iloc[index]\n",
    "    \n",
    "    # Compare if its the same\n",
    "    if (temp == temppart).all():\n",
    "        print(f\"{col} is the same\")\n",
    "    else:\n",
    "        print(f\"{col} is not the same\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7485107191e2190"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the original data and add the imputed ca125 to it"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9d3be493b3b484f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MAYO_w_CA125 = pd.read_csv(\"../0.1. Cleaned_data/MAYO_subdag.csv\")\n",
    "MAYO_w_CA125['CA125'] = MAYO_part['CA125']\n",
    "\n",
    "for col in MAYO_w_CA125.columns:\n",
    "    if col not in MAYO_part.columns:\n",
    "        MAYO_part[col] = MAYO_w_CA125[col]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2fdba53ab8778a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the imputed data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63850e3a8983af5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MAYO_w_CA125.to_csv('../0.2. Imputed_data/MayoCA125_wPIP_MidasPy.csv', index=False)\n",
    "MAYO_part.to_csv('../0.2. Imputed_data/Mayo_wPIP_fullimp_MidasPy.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "558127d84f858b6e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
