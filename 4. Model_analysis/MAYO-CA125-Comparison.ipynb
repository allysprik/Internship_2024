{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Author: Ally Sprik\n",
    "### Last-updated: 25-02-2024\n",
    "\n",
    "Goal of this notebook is to compare the pure MAYO validation with CA125 imputed MAYO validation and the complete imputed MAYO validation. \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44e6ff8b477843ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyAgrum as gum\n",
    "import pyAgrum.lib.notebook as gnb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#net = gum.loadBN(\"../0.3. Original_Casper_files/Results/Casper_fitted_763.net\")\n",
    "net = gum.loadBN(\"../3. Model/Fitted_Networks/R_WP_all_train_952.net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the data, select only the rows that have a LNM value in the original dataset and select these rows in the imputed datasets."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28d55ea4d7790f69"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_or = pd.read_csv(\"../0.1. Cleaned_data/MAYO_subdag.csv\").dropna(subset=[\"LNM\"])\n",
    "df_CA125 = pd.read_csv(\"../0.2. Imputed_data/Informed_imputation_CA125.csv\", sep=\",\")\n",
    "df_compl = pd.read_csv(\"../0.2. Imputed_data/MAYO-imputed-complete.csv\", sep=\";\")\n",
    "\n",
    "index = df_or.index\n",
    "df_CA125 = df_CA125.iloc[index]\n",
    "df_compl = df_compl.iloc[index]\n",
    "\n",
    "df_or = df_or.reset_index(drop=True)\n",
    "df_CA125 = df_CA125.reset_index(drop=True)\n",
    "df_compl = df_compl.reset_index(drop=True)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2604f09bf23ca951"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fix labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc16ebfa2120c973"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_or[\"Cytology\"].replace({\"no\": \"benign\", \"yes\":\"malignant\"}, inplace=True)\n",
    "df_CA125[\"Cytology\"].replace({\"no\": \"benign\", \"yes\":\"malignant\"}, inplace=True)\n",
    "df_compl[\"Cytology\"].replace({\"no\": \"benign\", \"yes\":\"malignant\"}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1648af2d232c8157"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the evidence sets and the target sets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a3e4ebeeb49e458"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evidence_columns = [\"ER\", \"PR\", \"p53\", \"L1CAM\", \"CA125\", \"Platelets\", \"POLE\", \"MSI\", \"PreoperativeGrade\", \"Cytology\"]\n",
    "\n",
    "df_or_evi = df_or[evidence_columns]\n",
    "df_CA125_evi = df_CA125[evidence_columns]\n",
    "df_compl_evi = df_compl[evidence_columns]\n",
    "\n",
    "targets = df_or[[\"LNM_micromacro\", \"Survival5yr\"]]\n",
    "targets.rename(columns={\"LNM_micromacro\": \"LNM\"}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7abb83957087a62c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a function to loop through the evidence and get the results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92b0450629812f14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to loop through the evidence and get the results\n",
    "\n",
    "def getProbabilities(model,evidence, Surv = \"Survival5yr\"):\n",
    "    resultsLNM = []\n",
    "    resultsSurvival = []\n",
    "    \n",
    "    for i in range(len(evidence)):\n",
    "        evidencerow = evidence.iloc[i]\n",
    "        evidencerow = evidencerow.dropna().to_dict()\n",
    "\n",
    "        result = gum.getPosterior(model, evs = evidencerow, target = \"LNM\")\n",
    "        resultsLNM.append(result)\n",
    "        \n",
    "        result = gum.getPosterior(model, evs = evidencerow, target = Surv)\n",
    "        resultsSurvival.append(result)\n",
    "        \n",
    "    return resultsLNM, resultsSurvival"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "259469941b2d203f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the probabilities for the original dataset, the CA125 dataset and the complete dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca1ccb0a9d5ee054"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the probabilities for the original dataset\n",
    "print(\"Original dataset\")\n",
    "or_LNM_res, or_Surv_res = getProbabilities(net, df_or_evi)\n",
    "# Get the probabilities for the CA125 dataset\n",
    "print(\"CA125 dataset\")\n",
    "CA125_LNM_res, CA125_Surv_res = getProbabilities(net, df_CA125_evi)\n",
    "# Get the probabilities for the complete dataset\n",
    "print(\"Complete dataset\")\n",
    "compl_LNM_res, compl_Surv_res = getProbabilities(net, df_compl_evi)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d2a29ae30134c11"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define a function to get the results based on a threshold for the probability"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4981f737c2b3b4c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a function to get the results based on a threshold for the probability\n",
    "def getResultsLNM(results, threshold, target):\n",
    "    res = []\n",
    "    \n",
    "    for i in range(len(results)):\n",
    "        if results[i].argmax()[0][0][target] == 1 and results[i].argmax()[1] > threshold:\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(0)\n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "def getResultsSurv(results, threshold, target, Surv_tar = 1):\n",
    "    res = []\n",
    "    \n",
    "    for i in range(len(results)):\n",
    "        if results[i].argmax()[0][0][target] == Surv_tar and results[i].argmax()[1] > threshold:\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(0)\n",
    "    return pd.DataFrame(res)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d58041037aeaab5c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define a function to get the probability results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b916480f3214ad87"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getProbResults(results, target):\n",
    "    res = []\n",
    "    \n",
    "    for i in range(len(results)):\n",
    "        res.append(results[i][target])\n",
    "    return pd.DataFrame(res)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bfcacf4200e127"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the results for the original dataset, the CA125 dataset and the complete dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95534e67c5a1e573"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "org_LNM_res_prob = getProbResults(or_LNM_res, 1)\n",
    "org_Surv_res_prob = getProbResults(or_Surv_res, 1)\n",
    "\n",
    "CA125_LNM_res_prob = getProbResults(CA125_LNM_res, 1)\n",
    "CA125_Surv_res_prob = getProbResults(CA125_Surv_res, 1)\n",
    "\n",
    "compl_LNM_res_prob = getProbResults(compl_LNM_res, 1)\n",
    "compl_Surv_res_prob = getProbResults(compl_Surv_res, 1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0b36d89095e4779"
  },
  {
   "cell_type": "markdown",
   "source": [
    "defing a function to get the metrics and the slim (non-threshold) metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee65f5b5087bdeb8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, brier_score_loss\n",
    "# Find the accuracy, roc auc, precision and recall for the results and the targets data\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, confusion_matrix, log_loss\n",
    "\n",
    "def getMetrics(results, targets):\n",
    "    TP = confusion_matrix(targets, results)[1][1]\n",
    "    TN = confusion_matrix(targets, results)[0][0]\n",
    "    FP = confusion_matrix(targets, results)[0][1]\n",
    "    FN = confusion_matrix(targets, results)[1][0]\n",
    "    \n",
    "    accuracy = accuracy_score(targets, results)\n",
    "    roc_auc = roc_auc_score(targets, results)\n",
    "    precision = precision_score(targets, results)\n",
    "    TPR = recall_score(targets, results)\n",
    "    TNR = TN / (TN + FP)\n",
    "    \n",
    "    f1 = 2 * (precision * TPR) / (precision + TPR)\n",
    "    brier = np.mean((results - targets)**2)\n",
    "    loglike = log_loss(targets, results)\n",
    "    \n",
    "    x = pd.DataFrame([accuracy, roc_auc, precision, TPR,TNR, f1, brier, loglike], index=[\"Accuracy\", \"ROC AUC\", \"Precision (PPV)\", \"TPR (Recall/Sens)\",\"TNR (Spec)\", \"F1\", \"Brier\", \"Log Loss\"])\n",
    "    return x\n",
    "\n",
    "def getSlimMetrics(results, targets):\n",
    "    # Get ROC AUC, Log Loss, Brier, and N Predicted/N Observed\n",
    "    curve = roc_curve(targets, results, pos_label=1)\n",
    "    ROC = round(roc_auc_score(targets, results), 4)\n",
    "    LL = round(log_loss(targets, results), 4)\n",
    "    Brier = round(brier_score_loss(targets, results), 4)\n",
    "    N_pred = results.sum()[0]\n",
    "    N_obs = int(targets.sum())\n",
    "    N_br = f\"{int(N_pred)}/{int(N_obs)}\"\n",
    "    Ratio = round(N_pred/N_obs, 4)\n",
    "    \n",
    "    x = pd.DataFrame([ROC, LL, Brier, N_br, Ratio], index=[\"ROC AUC\", \"Log Loss\", \"Brier\", \"N Predicted/N Observed\", \"Ratio\"])\n",
    "    return x\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4454c4f598253d6f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Encode the targets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a00112595589bb8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Encode targets\n",
    "targets[\"LNM\"] = targets[\"LNM\"].replace({\"yes\": 1, \"no\": 0})\n",
    "targets[\"Survival5yr\"] = targets[\"Survival5yr\"].replace({\"yes\": 1, \"no\": 0})\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23f4c8b435ec2b4b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the metrics for the original data, the CA125 data and the complete data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6c03ead74a24d01"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the metrics for the original data\n",
    "org_LNM_metrics = getSlimMetrics(org_LNM_res_prob, targets[\"LNM\"])\n",
    "org_Surv_metrics = getSlimMetrics(org_Surv_res_prob, targets[\"Survival5yr\"])\n",
    "# Get the metrics for the CA125 data\n",
    "CA125_LNM_metrics = getSlimMetrics(CA125_LNM_res_prob, targets[\"LNM\"])\n",
    "CA125_Surv_metrics = getSlimMetrics(CA125_Surv_res_prob, targets[\"Survival5yr\"])\n",
    "# Get the metrics for the complete data\n",
    "compl_LNM_metrics = getSlimMetrics(compl_LNM_res_prob, targets[\"LNM\"])\n",
    "compl_Surv_metrics = getSlimMetrics(compl_Surv_res_prob, targets[\"Survival5yr\"])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d812def5c5154018"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Concatenate the metrics to compare between the models LNM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12b893cfe1dda710"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LNM_metrics = pd.concat([org_LNM_metrics, CA125_LNM_metrics, compl_LNM_metrics], axis=1)\n",
    "LNM_metrics = LNM_metrics.round(3)\n",
    "LNM_metrics.columns = [\"Original data\", \"CA125\", \"Imputed data\"]\n",
    "LNM_metrics\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6ceabb590d3b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Concatenate the metrics to compare between the models Survival"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc06eaba491c7421"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Surv_metrics = pd.concat([org_Surv_metrics, CA125_Surv_metrics, compl_Surv_metrics], axis=1)\n",
    "Surv_metrics = Surv_metrics.round(3)\n",
    "Surv_metrics.columns = [\"Original data\", \"CA125\", \"Imputed data\"]\n",
    "Surv_metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94d0da99acf0e86"
  },
  {
   "cell_type": "markdown",
   "source": [
    "load other sets to compare the distribution of the CA125 values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9de215bd0c8f00e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compare between the distribution of imputed CA125 and PIPENDO/Training CA125\n",
    "df_PIP = pd.read_csv(\"../0.1. Cleaned_data/Pipendo_with_risk_levels.csv\")\n",
    "df_Training = pd.read_csv(\"../0.1. Cleaned_data/Training_TCGA_Risk_levels.csv\")\n",
    "df_Tub = pd.read_csv(\"../0.1. Cleaned_data/Tubingen_risk_groups.csv\")\n",
    "\n",
    "# Get the CA125 values for the original data\n",
    "CA125_orig = df_or[\"CA125\"].replace({\"lt_35\": \"<35\", \"ge_35\": \">=35\"})\n",
    "# Get the CA125 values for the imputed data\n",
    "CA125_imputed = df_compl[\"CA125\"].replace({\"lt_35\": \"<35\", \"ge_35\": \">=35\"})\n",
    "# Get the CA125 values for the PIPENDO data\n",
    "CA125_PIP = df_PIP[\"CA125_PREOP_bi\"].replace({\"<35 U/mL (=normal)\": \"<35\", \"=/>35 U/mL (=abnormal)\": \">=35\"})\n",
    "# Get the CA125 values for the Training data\n",
    "CA125_Training = df_Training[\"CA125_PREOP_bi\"].replace({0: \"<35\", 1: \">=35\"})\n",
    "# Get the CA125 values for the Tubingen data\n",
    "CA125_Tub = df_Tub[\"CA125_bi\"].replace({\"<=35\": \"<35\", \">35\": \">=35\"})\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17342896b27466b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a plot to compare the distribution of the CA125 values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8302020317fb6802"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a dataframe with the CA125 count values normalized with an N\n",
    "N_or = len(CA125_orig.dropna())\n",
    "N_imputed = len(CA125_imputed.dropna())\n",
    "N_PIP = len(CA125_PIP.dropna())\n",
    "N_Training = len(CA125_Training.dropna())\n",
    "N_Tub = len(CA125_Tub.dropna())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "set_matplotlib_formats(\"png\")\n",
    "\n",
    "CA125_counts = pd.DataFrame([CA125_orig.value_counts(normalize=True), CA125_imputed.value_counts(normalize=True), CA125_PIP.value_counts(normalize=True), CA125_Training.value_counts(normalize=True), CA125_Tub.value_counts(normalize=True)], index=[f\"Original N={N_or}\", f\"Imputed N={N_imputed}\", f\"PIPENDO N={N_PIP}\", f\"Training N={N_Training}\", f\"Tubingen N={N_Tub}\"])\n",
    "\n",
    "CA125_counts.plot(kind=\"bar\", figsize=(10,5))\n",
    "plt.title(\"CA125 distribution\")\n",
    "plt.ylabel(\"Normalized frequency\")\n",
    "plt.xlabel(\"Datasets\")\n",
    "plt.xticks(rotation=0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea83abd1afa1db60"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
